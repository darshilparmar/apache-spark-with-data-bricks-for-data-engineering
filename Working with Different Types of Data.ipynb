{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "364f94aa-3999-4194-ab63-b9f8ff8ed4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\")\\\n",
    "\t.option(\"header\", \"true\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .load(\"data/retail-data/by-day/2010-12-01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01602614-9664-40be-817e-bdb760def2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: timestamp (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: double (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d40fc8aa-a1ec-4cbb-ab4d-06df4555af0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "812bf40b-07a3-43fc-a90e-c623b507e824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[5: int, five: string, 5.0: double]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "df.select(lit(5), lit(\"five\"), lit(5.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4499cd9d-0fa1-4ab9-a1bb-bbfc6d9c8020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------------------------+\n",
      "|InvoiceNo|Description                        |\n",
      "+---------+-----------------------------------+\n",
      "|536365   |WHITE HANGING HEART T-LIGHT HOLDER |\n",
      "|536365   |WHITE METAL LANTERN                |\n",
      "|536365   |CREAM CUPID HEARTS COAT HANGER     |\n",
      "|536365   |KNITTED UNION FLAG HOT WATER BOTTLE|\n",
      "|536365   |RED WOOLLY HOTTIE WHITE HEART.     |\n",
      "+---------+-----------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df.where(col(\"InvoiceNo\") == 536365).select(\"InvoiceNo\", \"Description\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0f81ea8-2221-472f-ba11-8a731e19e6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description                        |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+-----------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|536365   |85123A   |WHITE HANGING HEART T-LIGHT HOLDER |6       |2010-12-01 08:26:00|2.55     |17850.0   |United Kingdom|\n",
      "|536365   |71053    |WHITE METAL LANTERN                |6       |2010-12-01 08:26:00|3.39     |17850.0   |United Kingdom|\n",
      "|536365   |84406B   |CREAM CUPID HEARTS COAT HANGER     |8       |2010-12-01 08:26:00|2.75     |17850.0   |United Kingdom|\n",
      "|536365   |84029G   |KNITTED UNION FLAG HOT WATER BOTTLE|6       |2010-12-01 08:26:00|3.39     |17850.0   |United Kingdom|\n",
      "|536365   |84029E   |RED WOOLLY HOTTIE WHITE HEART.     |6       |2010-12-01 08:26:00|3.39     |17850.0   |United Kingdom|\n",
      "+---------+---------+-----------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------+---------+-----------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description                  |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+-----------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|536366   |22633    |HAND WARMER UNION JACK       |6       |2010-12-01 08:28:00|1.85     |17850.0   |United Kingdom|\n",
      "|536366   |22632    |HAND WARMER RED POLKA DOT    |6       |2010-12-01 08:28:00|1.85     |17850.0   |United Kingdom|\n",
      "|536367   |84879    |ASSORTED COLOUR BIRD ORNAMENT|32      |2010-12-01 08:34:00|1.69     |13047.0   |United Kingdom|\n",
      "|536367   |22745    |POPPY'S PLAYHOUSE BEDROOM    |6       |2010-12-01 08:34:00|2.1      |13047.0   |United Kingdom|\n",
      "|536367   |22748    |POPPY'S PLAYHOUSE KITCHEN    |6       |2010-12-01 08:34:00|2.1      |13047.0   |United Kingdom|\n",
      "+---------+---------+-----------------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(\"InvoiceNo = 536365\").show(5, False)\n",
    "\n",
    "df.where(\"InvoiceNo <> 536365\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9806dc3f-1a4d-4a2c-a312-7c18f7015554",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import instr\n",
    "\n",
    "priceFilter = col(\"UnitPrice\") > 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88e10f00-2fe2-4855-a752-177b2bdb5d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'(UnitPrice > 600)'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priceFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16c76222-e31b-4f2e-9e5b-a5c6968e4898",
   "metadata": {},
   "outputs": [],
   "source": [
    "descripFilter = instr(df.Description, \"POSTAGE\") >= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69a89502-d150-4e27-b295-7be252ea4aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|   Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536592|      DOT|DOTCOM POSTAGE|       1|2010-12-01 17:06:00|   607.49|      NULL|United Kingdom|\n",
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df.StockCode.isin(\"DOT\")).where(priceFilter & descripFilter).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e35aa1f3-dec9-4b91-9d44-3d6323bc7600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|CustomerId|      realQuantity|\n",
      "+----------+------------------+\n",
      "|   17850.0|242.08999999999997|\n",
      "|   17850.0|          421.7156|\n",
      "+----------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr, pow\n",
    "fabricatedQuantity = pow(col(\"Quantity\") * col(\"UnitPrice\"), 2) + 8\n",
    "df.select(expr(\"CustomerId\"), fabricatedQuantity.alias(\"realQuantity\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e12e1770-359f-4f17-bcd7-1f5d9f37aaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n",
      "|round(2.5, 0)|bround(2.5, 0)|\n",
      "+-------------+--------------+\n",
      "|          3.0|           2.0|\n",
      "|          3.0|           2.0|\n",
      "+-------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit, round, bround\n",
    "df.select(round(lit(\"2.5\")), bround(lit(\"2.5\"))).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "083f4b7d-1722-4bd2-bbee-f888fe47c9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|         Description|initcap(Description)|\n",
      "+--------------------+--------------------+\n",
      "|WHITE HANGING HEA...|White Hanging Hea...|\n",
      "| WHITE METAL LANTERN| White Metal Lantern|\n",
      "|CREAM CUPID HEART...|Cream Cupid Heart...|\n",
      "|KNITTED UNION FLA...|Knitted Union Fla...|\n",
      "|RED WOOLLY HOTTIE...|Red Woolly Hottie...|\n",
      "|SET 7 BABUSHKA NE...|Set 7 Babushka Ne...|\n",
      "|GLASS STAR FROSTE...|Glass Star Froste...|\n",
      "|HAND WARMER UNION...|Hand Warmer Union...|\n",
      "|HAND WARMER RED P...|Hand Warmer Red P...|\n",
      "|ASSORTED COLOUR B...|Assorted Colour B...|\n",
      "|POPPY'S PLAYHOUSE...|Poppy's Playhouse...|\n",
      "|POPPY'S PLAYHOUSE...|Poppy's Playhouse...|\n",
      "|FELTCRAFT PRINCES...|Feltcraft Princes...|\n",
      "|IVORY KNITTED MUG...|Ivory Knitted Mug...|\n",
      "|BOX OF 6 ASSORTED...|Box Of 6 Assorted...|\n",
      "|BOX OF VINTAGE JI...|Box Of Vintage Ji...|\n",
      "|BOX OF VINTAGE AL...|Box Of Vintage Al...|\n",
      "|HOME BUILDING BLO...|Home Building Blo...|\n",
      "|LOVE BUILDING BLO...|Love Building Blo...|\n",
      "|RECIPE BOX WITH M...|Recipe Box With M...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import initcap\n",
    "df.select(col(\"Description\"), initcap(col(\"Description\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e29f96e1-2c9d-4e41-aa1a-6b1cb65cf59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------------+\n",
      "|         Description|  lower(Description)|upper(lower(Description))|\n",
      "+--------------------+--------------------+-------------------------+\n",
      "|WHITE HANGING HEA...|white hanging hea...|     WHITE HANGING HEA...|\n",
      "| WHITE METAL LANTERN| white metal lantern|      WHITE METAL LANTERN|\n",
      "+--------------------+--------------------+-------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lower, upper\n",
    "df.select(col(\"Description\"), lower(col(\"Description\")), upper(lower(col(\"Description\")))).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77d17daa-8676-4e36-b52c-46696686ec41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+---+----------+\n",
      "|  ltrim|  rtrim| trim| lp|        rp|\n",
      "+-------+-------+-----+---+----------+\n",
      "|HELLO  |  HELLO|HELLO|HEL|HELLO     |\n",
      "|HELLO  |  HELLO|HELLO|HEL|HELLO     |\n",
      "+-------+-------+-----+---+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit, ltrim, rtrim, rpad, lpad, trim\n",
    "df.select(\n",
    "ltrim(lit(\"  HELLO  \")).alias(\"ltrim\"),\n",
    "rtrim(lit(\"  HELLO  \")).alias(\"rtrim\"),\n",
    "trim(lit(\"  HELLO  \")).alias(\"trim\"),\n",
    "lpad(lit(\"HELLO\"), 3, \" \").alias(\"lp\"),\n",
    "rpad(lit(\"HELLO\"), 10, \" \").alias(\"rp\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6c5787d-ce50-40dd-8764-5f30073e37ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = false)\n",
      " |-- today: date (nullable = false)\n",
      " |-- now: timestamp (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import current_date, current_timestamp\n",
    "dateDF = spark.range(10)\\\n",
    "\t.withColumn(\"today\", current_date())\\\n",
    "\t.withColumn(\"now\", current_timestamp())\n",
    "\n",
    "dateDF.createOrReplaceTempView(\"dateTable\")\n",
    "\n",
    "dateDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29550e46-3c2f-4927-bd8a-3a91aed23a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+\n",
      "| id|     today|                 now|\n",
      "+---+----------+--------------------+\n",
      "|  0|2024-01-04|2024-01-04 19:30:...|\n",
      "|  1|2024-01-04|2024-01-04 19:30:...|\n",
      "|  2|2024-01-04|2024-01-04 19:30:...|\n",
      "|  3|2024-01-04|2024-01-04 19:30:...|\n",
      "|  4|2024-01-04|2024-01-04 19:30:...|\n",
      "|  5|2024-01-04|2024-01-04 19:30:...|\n",
      "|  6|2024-01-04|2024-01-04 19:30:...|\n",
      "|  7|2024-01-04|2024-01-04 19:30:...|\n",
      "|  8|2024-01-04|2024-01-04 19:30:...|\n",
      "|  9|2024-01-04|2024-01-04 19:30:...|\n",
      "+---+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dateDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6601da0a-4a77-4fd9-851a-be978df5c1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|date_sub(today, 5)|date_add(today, 5)|\n",
      "+------------------+------------------+\n",
      "|        2023-12-30|        2024-01-09|\n",
      "+------------------+------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import date_add, date_sub\n",
    "dateDF.select(date_sub(col(\"today\"), 5), date_add(col(\"today\"), 5)).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2aefe795-1c20-413e-b313-270bea177d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|datediff(week_ago, today)|\n",
      "+-------------------------+\n",
      "|                       -7|\n",
      "+-------------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "+--------------------------------+\n",
      "|months_between(start, end, true)|\n",
      "+--------------------------------+\n",
      "|                    -16.67741935|\n",
      "+--------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import datediff, months_between, to_date\n",
    "dateDF.withColumn(\"week_ago\", date_sub(col(\"today\"), 7))\\\n",
    "\t.select(datediff(col(\"week_ago\"), col(\"today\"))).show(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0796558f-ac8b-40d3-a222-09323a5ef04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|months_between(start, end, true)|\n",
      "+--------------------------------+\n",
      "|                    -16.67741935|\n",
      "+--------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dateDF.select(\n",
    "      to_date(lit(\"2016-01-01\")).alias(\"start\"),\n",
    "      to_date(lit(\"2017-05-22\")).alias(\"end\"))\\\n",
    "      .select(months_between(col(\"start\"), col(\"end\"))).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dfcdbe98-57a0-4f02-b9a4-d1774ce96527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|to_date(2016-20-12)|to_date(2017-12-11)|\n",
      "+-------------------+-------------------+\n",
      "|               NULL|         2017-12-11|\n",
      "+-------------------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dateDF.select(to_date(lit(\"2016-20-12\")),to_date(lit(\"2017-12-11\"))).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d867461-e006-4577-898b-1624efc4a714",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "\n",
    "dateFormat = \"yyyy-dd-MM\"\n",
    "\n",
    "cleanDateDF = spark.range(1).select(\n",
    "  to_date(lit(\"2017-12-11\"), dateFormat).alias(\"date\"),\n",
    "  to_date(lit(\"2017-20-12\"), dateFormat).alias(\"date2\"))\n",
    "cleanDateDF.createOrReplaceTempView(\"dateTable2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1410c3ff-7eb5-4b78-b759-227e31bc039a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|      date|     date2|\n",
      "+----------+----------+\n",
      "|2017-11-12|2017-12-20|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleanDateDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b17f8b21-c25d-400f-8a92-d78d755c2307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import struct\n",
    "\n",
    "complexDF = df.select(struct(\"Description\", \"InvoiceNo\").alias(\"complex\"))\n",
    "\n",
    "complexDF.createOrReplaceTempView(\"complexDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "96d74762-4be8-4e8c-8cb5-fc855ca667dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             complex|\n",
      "+--------------------+\n",
      "|{WHITE HANGING HE...|\n",
      "|{WHITE METAL LANT...|\n",
      "|{CREAM CUPID HEAR...|\n",
      "|{KNITTED UNION FL...|\n",
      "|{RED WOOLLY HOTTI...|\n",
      "|{SET 7 BABUSHKA N...|\n",
      "|{GLASS STAR FROST...|\n",
      "|{HAND WARMER UNIO...|\n",
      "|{HAND WARMER RED ...|\n",
      "|{ASSORTED COLOUR ...|\n",
      "|{POPPY'S PLAYHOUS...|\n",
      "|{POPPY'S PLAYHOUS...|\n",
      "|{FELTCRAFT PRINCE...|\n",
      "|{IVORY KNITTED MU...|\n",
      "|{BOX OF 6 ASSORTE...|\n",
      "|{BOX OF VINTAGE J...|\n",
      "|{BOX OF VINTAGE A...|\n",
      "|{HOME BUILDING BL...|\n",
      "|{LOVE BUILDING BL...|\n",
      "|{RECIPE BOX WITH ...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complexDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "438a2379-6c19-44cd-9ac5-c5d48a46e4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|InvoiceNo|\n",
      "+---------+\n",
      "|   536365|\n",
      "|   536365|\n",
      "|   536365|\n",
      "|   536365|\n",
      "|   536365|\n",
      "|   536365|\n",
      "|   536365|\n",
      "|   536366|\n",
      "|   536366|\n",
      "|   536367|\n",
      "|   536367|\n",
      "|   536367|\n",
      "|   536367|\n",
      "|   536367|\n",
      "|   536367|\n",
      "|   536367|\n",
      "|   536367|\n",
      "|   536367|\n",
      "|   536367|\n",
      "|   536367|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complexDF.select(\"complex.InvoiceNo\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed58df32-74b4-46b9-ba62-4f1982097753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "| complex.Description|\n",
      "+--------------------+\n",
      "|WHITE HANGING HEA...|\n",
      "| WHITE METAL LANTERN|\n",
      "|CREAM CUPID HEART...|\n",
      "|KNITTED UNION FLA...|\n",
      "|RED WOOLLY HOTTIE...|\n",
      "|SET 7 BABUSHKA NE...|\n",
      "|GLASS STAR FROSTE...|\n",
      "|HAND WARMER UNION...|\n",
      "|HAND WARMER RED P...|\n",
      "|ASSORTED COLOUR B...|\n",
      "|POPPY'S PLAYHOUSE...|\n",
      "|POPPY'S PLAYHOUSE...|\n",
      "|FELTCRAFT PRINCES...|\n",
      "|IVORY KNITTED MUG...|\n",
      "|BOX OF 6 ASSORTED...|\n",
      "|BOX OF VINTAGE JI...|\n",
      "|BOX OF VINTAGE AL...|\n",
      "|HOME BUILDING BLO...|\n",
      "|LOVE BUILDING BLO...|\n",
      "|RECIPE BOX WITH M...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complexDF.select(col(\"complex\").getField(\"Description\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fffc633e-088a-4946-b9d6-d598455a6ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|split(Description,  , -1)|\n",
      "+-------------------------+\n",
      "|     [WHITE, HANGING, ...|\n",
      "|     [WHITE, METAL, LA...|\n",
      "|     [CREAM, CUPID, HE...|\n",
      "|     [KNITTED, UNION, ...|\n",
      "|     [RED, WOOLLY, HOT...|\n",
      "|     [SET, 7, BABUSHKA...|\n",
      "|     [GLASS, STAR, FRO...|\n",
      "|     [HAND, WARMER, UN...|\n",
      "|     [HAND, WARMER, RE...|\n",
      "|     [ASSORTED, COLOUR...|\n",
      "|     [POPPY'S, PLAYHOU...|\n",
      "|     [POPPY'S, PLAYHOU...|\n",
      "|     [FELTCRAFT, PRINC...|\n",
      "|     [IVORY, KNITTED, ...|\n",
      "|     [BOX, OF, 6, ASSO...|\n",
      "|     [BOX, OF, VINTAGE...|\n",
      "|     [BOX, OF, VINTAGE...|\n",
      "|     [HOME, BUILDING, ...|\n",
      "|     [LOVE, BUILDING, ...|\n",
      "|     [RECIPE, BOX, WIT...|\n",
      "+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split\n",
    "\n",
    "\n",
    "df.select(split(col(\"Description\"), \" \")).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "93dc81c3-8477-423a-8f99-aeba8046147a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|array_col[0]|array_col[1]|\n",
      "+------------+------------+\n",
      "|       WHITE|     HANGING|\n",
      "|       WHITE|       METAL|\n",
      "|       CREAM|       CUPID|\n",
      "|     KNITTED|       UNION|\n",
      "|         RED|      WOOLLY|\n",
      "|         SET|           7|\n",
      "|       GLASS|        STAR|\n",
      "|        HAND|      WARMER|\n",
      "|        HAND|      WARMER|\n",
      "|    ASSORTED|      COLOUR|\n",
      "|     POPPY'S|   PLAYHOUSE|\n",
      "|     POPPY'S|   PLAYHOUSE|\n",
      "|   FELTCRAFT|    PRINCESS|\n",
      "|       IVORY|     KNITTED|\n",
      "|         BOX|          OF|\n",
      "|         BOX|          OF|\n",
      "|         BOX|          OF|\n",
      "|        HOME|    BUILDING|\n",
      "|        LOVE|    BUILDING|\n",
      "|      RECIPE|         BOX|\n",
      "+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(split(col(\"Description\"), \" \").alias(\"array_col\")).selectExpr(\"array_col[0]\",\"array_col[1]\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "52911a23-70e4-4082-ae47-f3eb3b2cd0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------+\n",
      "|         Description|InvoiceNo|exploded|\n",
      "+--------------------+---------+--------+\n",
      "|WHITE HANGING HEA...|   536365|   WHITE|\n",
      "|WHITE HANGING HEA...|   536365| HANGING|\n",
      "+--------------------+---------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "\n",
    "df.withColumn(\"splitted\", split(col(\"Description\"), \" \"))\\\n",
    "\t.withColumn(\"exploded\", explode(col(\"splitted\")))\\\n",
    "    .select(\"Description\", \"InvoiceNo\", \"exploded\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "08b944d2-4bbb-40cc-b576-cb078fa8d293",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonDF = spark.range(1).selectExpr(\"\"\"'{\"myJSONKey\" : {\"myJSONValue\" : [1, 2, 3]}}' as jsonString\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aed6729b-2e94-4df5-831e-e844044717d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|          jsonString|\n",
      "+--------------------+\n",
      "|{\"myJSONKey\" : {\"...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jsonDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "acdc320d-aed0-4935-b5c9-02c50fec1b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "udfExampleDF = spark.range(5).toDF(\"num\")\n",
    "\n",
    "def power3(double_value):\n",
    "    return double_value ** 3\n",
    "\n",
    "power3(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dd42542d-fbb7-4054-9662-09443797c58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "power3udf = udf(power3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7517a439-dd9d-499e-b6b4-eea46a6e1838",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
